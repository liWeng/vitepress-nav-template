## 业务系统性能排查方案

## 编写人员 



## 性能问题描述

业务系统在使用过程中如遇到系统请求缓慢，无法使用等问题需要进行问题排查，包括基础环境测试，应用排查、数据库排查、中间件排查等。

## 上线或压测前检查

## 环境性能测试 

### 服务器带宽测试
带宽测试分为服务器内网带宽测试，客户网络到服务器机房带宽测试，测试工具使用qperf,测试的两台服务器必须都安装iperf3 qperf
```
yum install iperf3 qperf -y
```
#### 带宽测试
服务端启动接收服务，-lp 指定端口为12345， 如果不指定默认为19765
```
qperf 
```
客户端执行测试命令,注意：需要关闭服务端的防火墙，否则访问不通
```
qperf <服务端IP>  -oo msg_size:1:64K:*2 -vu tcp_bw
```
#### 测试结果分析，此结果为天津服务器带宽测试结果
可以看到随着发送数据越来越多，带宽不再变化，带宽为11.8 MB/sec 左右
```
tcp_bw:
    bw        =  1.46 MB/sec
    msg_size  =     1 bytes
tcp_bw:
    bw        =  2.99 MB/sec
    msg_size  =     2 bytes
tcp_bw:
    bw        =  5.93 MB/sec
    msg_size  =     4 bytes
tcp_bw:
    bw        =  11.4 MB/sec
    msg_size  =     8 bytes
tcp_bw:
    bw        =  11.8 MB/sec
    msg_size  =    16 bytes
tcp_bw:
    bw        =  11.8 MB/sec
    msg_size  =    32 bytes
tcp_bw:
    bw        =  11.8 MB/sec
    msg_size  =    64 bytes
tcp_bw:
    bw        =  11.8 MB/sec
    msg_size  =   128 bytes
tcp_bw:
    bw        =  11.8 MB/sec
    msg_size  =   256 bytes
tcp_bw:
    bw        =  11.8 MB/sec
    msg_size  =   512 bytes
tcp_bw:
    bw        =  11.8 MB/sec
    msg_size  =     1 KiB (1,024)
tcp_bw:
    bw        =  11.8 MB/sec
    msg_size  =     2 KiB (2,048)
tcp_bw:
    bw        =  11.8 MB/sec
    msg_size  =     4 KiB (4,096)
tcp_bw:
    bw        =  11.8 MB/sec
    msg_size  =     8 KiB (8,192)
tcp_bw:
    bw        =  11.8 MB/sec
    msg_size  =    16 KiB (16,384)
tcp_bw:
    bw        =  11.7 MB/sec
    msg_size  =    32 KiB (32,768)
tcp_bw:
    bw        =  11.7 MB/sec
    msg_size  =    64 KiB (65,536)
```
### 网络延迟测试

#### 
客户端执行测试命令
```
qperf <服务端IP> -oo msg_size:1:64K:*2 tcp_lat
```
#### 测试结果分析（正常值<300us），此结果为天津服务器带宽测试结果
可以看到网络延迟为105微秒左右
```
tcp_lat:
    latency  =  105 us
tcp_lat:
    latency  =  105 us
tcp_lat:
    latency  =  103 us
tcp_lat:
    latency  =  105 us
tcp_lat:
    latency  =  112 us
tcp_lat:
    latency  =  119 us
tcp_lat:
    latency  =  154 us
```
### CPU 配置检查、性能测试

CPU 测试使用sysbench
```
yum install sysbench -y
```
```
#--cpu-max-prime: 素数生成数量的上限
#--threads: 线程数
#--time: 运行时长，单位秒
sysbench cpu --cpu-max-prime=20000 --threads=10 run --time=10
```
### 测试结果分析，此结果为唐山服务器测试结果
```
CPU speed:
    events per second:  3228.20

General statistics:
    total time:                          10.0029s
    total number of events:              32305

Latency (ms):
         min:                                    2.76
         avg:                                    3.10
         max:                                    7.59
         95th percentile:                        3.62
         sum:                               100000.49

Threads fairness:
    events (avg/stddev):           3230.5000/78.19
    execution time (avg/stddev):   10.0000/0.00
```

### 磁盘性能测试（要求较高，固态硬盘，机械硬盘，fc存储，分布式存储（各种架构）差别较大）,使用fio测试

#### 测试脚本
```

#!/bin/bash

#测试带宽
#Script of precondition:Bandwidth
fio --ioengine=libaio --direct=1 --thread --norandommap --filename=/dev/dfa --name=init_seq --output=init_seq.log --rw=write --bs=128k --numjobs=1 --iodepth=128 --loops=2 &

#测试128K顺序写
#128k Seq Write
fio --ioengine=libaio --randrepeat=0 --norandommap --thread --direct=1 --group_reporting --name=seq_write --ramp_time=300 --runtime=600 --time_based --numjobs=1 --iodepth=128 --filename=/dev/dfa --rw=write --bs=128k --output=dfa_128K_seqW.log --log_avg_msec=1000 --write_iops_log=dfa_128K_seqW_iops.log --write_lat_log=dfa_128K_seqW_lat.log &

#测试128K顺序读
#128k Seq Read
fio --ioengine=libaio --randrepeat=0 --norandommap --thread --direct=1 --group_reporting --name=seq_read --ramp_time=300 --runtime=3600 --time_based --numjobs=1 --iodepth=128 --filename=/dev/dfa --rw=read --bs=128k --output=dfa_128K_seqR.log --log_avg_msec=1000 --write_iops_log=dfa_128K_seqR_iops.log --write_lat_log=dfa_128K_seqR_lat.loga &

#测试4K IOPS
#Script of precondition:4K IOPS
fio --ioengine=libaio --direct=1 --thread --norandommap --filename=/dev/dfa --name=init_rand --output=init_rand.log --rw=randwrite --bs=4k --numjobs=2 --iodepth=64 --ramp_time=60  &

#测试4K随机写
#4k Random Write
fio --ioengine=libaio --randrepeat=0 --norandommap --thread --direct=1 --group_reporting --name=randwrite --ramp_time=300 --runtime=3600 --time_based --numjobs=4 --iodepth=64 --filename=/dev/dfa --rw=randwrite --bs=4k --output=dfa_4K_full_randW.log --log_avg_msec=1000 --write_iops_log=dfa_4K_full_randW_iops.log --write_lat_log=dfa_4K_full_randW_lat.log &

#测试4K随机读
#4k Random Read
fio --ioengine=libaio --randrepeat=0 --norandommap --thread --direct=1 --group_reporting --name=randread --ramp_time=300 --runtime=3600 --time_based --numjobs=4 --iodepth=64 --filename=/dev/dfa --rw=randread --bs=4k --output=dfa_4K_randR.log --log_avg_msec=1000 --write_iops_log=dfa_4K_randR_iops.log --write_lat_log=dfa_4K_randR_lat.log &
```

#### 测试结果分析，以下结果为唐山机房FC商业存储
##### 磁盘带宽测试
```
WRITE: bw=47.1MiB/s (49.4MB/s), 23.6MiB/s-23.6MiB/s (24.7MB/s-24.7MB/s), io=137GiB (147GB), run=2972018-2972018msec
```
128K顺序写
```
seq_write: (g=0): rw=write, bs=(R) 128KiB-128KiB, (W) 128KiB-128KiB, (T) 128KiB-128KiB, ioengine=libaio, iodepth=128
fio-3.1
Starting 1 thread

seq_write: (groupid=0, jobs=1): err= 0: pid=3456: Mon Aug 26 11:37:15 2019
  write: IOPS=6210, BW=776MiB/s (814MB/s)(227GiB/300018msec)
    slat (usec): min=5, max=819, avg=28.30, stdev=14.78
    clat (usec): min=3594, max=91980, avg=20578.43, stdev=1336.89
     lat (usec): min=3661, max=91997, avg=20607.00, stdev=1334.95
    clat percentiles (usec):
     |  1.00th=[16909],  5.00th=[18744], 10.00th=[19268], 20.00th=[19792],
     | 30.00th=[20055], 40.00th=[20317], 50.00th=[20579], 60.00th=[20841],
     | 70.00th=[21103], 80.00th=[21365], 90.00th=[21627], 95.00th=[22152],
     | 99.00th=[24249], 99.50th=[25297], 99.90th=[28967], 99.95th=[30802],
     | 99.99th=[46400]
   bw (  KiB/s): min=778904, max=813881, per=100.00%, avg=796622.10, stdev=4325.46, samples=600
   iops        : min= 6151, max= 6270, avg=6217.11, stdev=17.09, samples=300
  lat (msec)   : 4=0.01%, 10=0.02%, 20=24.61%, 50=75.38%, 100=0.01%
  cpu          : usr=5.49%, sys=17.50%, ctx=373470, majf=0, minf=17503
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=133.3%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwt: total=0,1863396,0, short=0,0,0, dropped=0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
  WRITE: bw=776MiB/s (814MB/s), 776MiB/s-776MiB/s (814MB/s-814MB/s), io=227GiB (244GB), run=300018-300018msec

```
##### 128K顺序读
```
seq_read: (g=0): rw=read, bs=(R) 128KiB-128KiB, (W) 128KiB-128KiB, (T) 128KiB-128KiB, ioengine=libaio, iodepth=128
fio-3.1
Starting 1 thread

seq_read: (groupid=0, jobs=1): err= 0: pid=3478: Mon Aug 26 11:43:55 2019
   read: IOPS=5896, BW=737MiB/s (773MB/s)(216GiB/300020msec)
    slat (usec): min=5, max=619, avg=20.96, stdev=10.06
    clat (msec): min=2, max=433, avg=21.69, stdev=12.61
     lat (msec): min=2, max=433, avg=21.71, stdev=12.61
    clat percentiles (msec):
     |  1.00th=[    7],  5.00th=[   12], 10.00th=[   15], 20.00th=[   18],
     | 30.00th=[   20], 40.00th=[   21], 50.00th=[   21], 60.00th=[   21],
     | 70.00th=[   22], 80.00th=[   24], 90.00th=[   27], 95.00th=[   31],
     | 99.00th=[   85], 99.50th=[  132], 99.90th=[  155], 99.95th=[  165],
     | 99.99th=[  211]
   bw (  KiB/s): min=271073, max=815772, per=100.00%, avg=756056.40, stdev=72707.60, samples=600
   iops        : min= 3721, max= 6326, avg=5901.50, stdev=402.48, samples=300
  lat (msec)   : 4=0.18%, 10=3.01%, 20=29.91%, 50=65.66%, 100=0.34%
  lat (msec)   : 250=0.90%, 500=0.01%
  cpu          : usr=1.60%, sys=16.38%, ctx=471678, majf=0, minf=1101
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=131.7%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%
     issued rwt: total=1768932,0,0, short=0,0,0, dropped=0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=128

Run status group 0 (all jobs):
   READ: bw=737MiB/s (773MB/s), 737MiB/s-737MiB/s (773MB/s-773MB/s), io=216GiB (232GB), run=300020-300020msec

```
##### 4K随机写
```
randwrite: (g=0): rw=randwrite, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
...
fio-3.1
Starting 4 threads

randwrite: (groupid=0, jobs=4): err= 0: pid=3544: Mon Aug 26 12:41:09 2019
  write: IOPS=11.8k, BW=46.3MiB/s (48.5MB/s)(13.6GiB/300009msec)
    slat (usec): min=2, max=264080, avg=322.82, stdev=2109.22
    clat (usec): min=508, max=1075.0k, avg=21291.47, stdev=17271.24
     lat (usec): min=514, max=1075.0k, avg=21614.51, stdev=17472.12
    clat percentiles (msec):
     |  1.00th=[    3],  5.00th=[    6], 10.00th=[    8], 20.00th=[   10],
     | 30.00th=[   12], 40.00th=[   15], 50.00th=[   17], 60.00th=[   21],
     | 70.00th=[   24], 80.00th=[   30], 90.00th=[   40], 95.00th=[   52],
     | 99.00th=[   87], 99.50th=[  106], 99.90th=[  169], 99.95th=[  203],
     | 99.99th=[  275]
   bw (  KiB/s): min= 2584, max=21520, per=25.05%, avg=11869.21, stdev=3164.11, samples=2400
   iops        : min= 1406, max= 4900, avg=2963.86, stdev=646.70, samples=1200
  lat (usec)   : 750=0.01%, 1000=0.02%
  lat (msec)   : 2=0.30%, 4=1.93%, 10=18.92%, 20=39.01%, 50=34.37%
  lat (msec)   : 100=4.86%, 250=0.57%, 500=0.02%, 750=0.01%, 1000=0.01%
  lat (msec)   : 2000=0.01%
  cpu          : usr=0.58%, sys=2.72%, ctx=278682, majf=0, minf=1657
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=133.5%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwt: total=0,3552963,0, short=0,0,0, dropped=0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
  WRITE: bw=46.3MiB/s (48.5MB/s), 46.3MiB/s-46.3MiB/s (48.5MB/s-48.5MB/s), io=13.6GiB (14.6GB), run=300009-300009msec
```
##### 4K随机读
```
randread: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
...
fio-3.1
Starting 4 threads

randread: (groupid=0, jobs=4): err= 0: pid=3570: Mon Aug 26 12:47:49 2019
   read: IOPS=3319, BW=12.0MiB/s (13.6MB/s)(3891MiB/300055msec)
    slat (usec): min=2, max=211829, avg=1192.17, stdev=7133.54
    clat (usec): min=970, max=790095, avg=75959.58, stdev=47698.21
     lat (usec): min=974, max=790098, avg=77152.28, stdev=48563.82
    clat percentiles (msec):
     |  1.00th=[   20],  5.00th=[   25], 10.00th=[   31], 20.00th=[   44],
     | 30.00th=[   52], 40.00th=[   57], 50.00th=[   63], 60.00th=[   71],
     | 70.00th=[   82], 80.00th=[  102], 90.00th=[  140], 95.00th=[  171],
     | 99.00th=[  232], 99.50th=[  271], 99.90th=[  409], 99.95th=[  472],
     | 99.99th=[  567]
   bw (  KiB/s): min= 1064, max= 5296, per=25.02%, avg=3323.06, stdev=1222.81, samples=2400
   iops        : min=  342, max= 1273, avg=830.23, stdev=299.70, samples=1200
  lat (usec)   : 1000=0.01%
  lat (msec)   : 2=0.01%, 4=0.01%, 10=0.06%, 20=1.21%, 50=27.20%
  lat (msec)   : 100=51.18%, 250=19.68%, 500=0.66%, 750=0.04%, 1000=0.01%
  cpu          : usr=0.17%, sys=0.60%, ctx=45946, majf=0, minf=1012
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=111.6%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued rwt: total=995889,0,0, short=0,0,0, dropped=0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: bw=12.0MiB/s (13.6MB/s), 12.0MiB/s-12.0MiB/s (13.6MB/s-13.6MB/s), io=3891MiB (4080MB), run=300055-300055msec
```

#### 内存配置检查、性能测试

对内存进行压力测试，可以申请大内存，放入后台无限测试，结果全部为OK则内存正常
```
memtester  [-p PHYSADDR] <MEMORY> [ITERATIONS]
```

### 配置检查
#### 应用配置检查
##### jvm参数、内存
```
1、检查docker-compose 配置文件 jvm内存参数是否正确
2、检查参数是否正确
```
##### tomcat并发线程数、连接数
```
1、登录到审计系统后可点击tomcat监控，选择对应的域和集群
2、可查看到tomcat并发线程数和最大连接数是否配置正确
```
##### 数据库连接池配置
```
1、检查配置文件的数据库连接池配置是否正确
2、可访问到Druid 主页查看数据源的连接池是否正确
```
##### redis连接池配置
```
检查以下配置
#最大连接数
fweb.cached.maxconn=500
#最大活动连接数
fweb.cached.maxidle=50
#最小活动连接数
fweb.cached.miniidle=50
```

#### 中间件配置
###### nginx
```
是否开启gzip压缩
#gzip
        gzip on;
        #client_max_body_size   4096m;
        gzip_disable "MSIE [1-6]\.";
        gzip_min_length 1k;
        gzip_vary on;
        gzip_proxied any;
        gzip_comp_level 6;
        gzip_buffers 16 8k;
        gzip_http_version 1.1;
        gzip_types text/css application/json application/javascript application/x-javascript text/xml application/xml application/xml+rss text/javascript image/jpeg image/gif image/png ;
```
###### zookeeper
```
jvm内存大小是否调整
export JVMFLAGS="-Xms512m -Xmx1024m $JVMFLAGS"
```
###### redis
```
timeout 是否修改
```
###### mysql
```
#innodb内存调整为当前服务器的60%左右
innodb_buffer_pool_size=2G
#根据内存大小调整为2-10左右
innodb_buffer_pool_instances=10
#调整log 缓冲，1-4M
innodb_log_buffer_size=2M
#调整log 文件大小。128M-2G
innodb_log_file_size =128M
#最大连接数100-2000
max_connections=100
#keybuffersize 128-512
key_buffer_size = 256M
#以下缓冲1-8M
read_buffer_size = 1M
sort_buffer_size = 1M
join_buffer_size = 1M
read_rnd_buffer_size=1M
#读写线程数2-8个
innodb_read_io_threads=8
innodb_write_io_threads=8

#集群配置
#wsrep
#slave处理线程数为服务器核数
wsrep_slave_threads=22
#fc limit 4096, gcache.size 1G
wsrep_provider_options = "gmcast.listen_addr=tcp://10.0.1.95:4667;ist.recv_addr=10.0.1.95:4668;gcache.size=1G;gcs.fc_limit=4096;" 

```
###### kafka
```
主题的分区数必须设置足够，否则影响性能
```
###### docker
```
查看以下配置文件 日志大小和个数，以及日志驱动是否正确，文件存放目录是否正确，存储驱动是否正确
/etc/docker/daemon.json 
{  
   "log-driver": "json-file",
   "log-opts": {    "max-size": "500m", "max-file": "10"   },
   "graph": "/data/docker",
   "storage-driver": "overlay2",
   "storage-opts": [   "overlay2.override_kernel_check=true ]  
}
```
###### 审计服务测试

### 上线后或压测过程中性能排查

#### loaderRunner 监控 压测结果分析每一步花费的时间

* 通过查看loaderRunner 的压测监控，查看每一个步骤响应时间
* 查看每个请求的平均响应时间，初步分析请求慢的地址
#### URL慢请求监控
* 通过使用审计工具URL count 分析工具，选择需要查询的域、集群、选择查询的时间段，
* 查询此时间段内的所有请求URL的平均响应时长，最大响应时长，最大响应时长发生的时间等，分析出请求慢的URL都有哪些

#### 数据库慢查询监控

* 通过使用审计工具Database Count分析工具，选择需要查询的域、集群、选择查询的时间段
* 查询此时间段内的所有请求SQL的平均响应时长，最大响应时长，最大响应时长发生的时间等以及参数，将慢查询进行分析。

#### tomcat 实时监控，数据库实时监控,
* 当服务出现响应超时节点CPU过高时可进入审计工具的Tomcat监控中查看当前阻塞的URl, 


#### 数据库实时监控，CPU过高
* 到数据库管理工具中执行以下sql " select * from information_schema.`PROCESSLIST` where  COMMAND <> 'Sleep' ", 查询当前正在运行的Sql，
* process list 详解查看以下内容,[点击跳转](https://git.365power.cn:8443/all-in-one/doc/blob/master/06-%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/MySqlProcessList%E7%8A%B6%E6%80%81%E8%AF%A6%E8%A7%A3.md)

#### 压测时cpu、内存的占用率，磁盘的吞吐，网络的吞吐。（pmm工具及linux命令）
* 登录到pmm监控工具中
* 到OS->System Overview中，选择响应的时间段
* 选择应用节点服务器，查看节点的CPU,内存，磁盘，网络是否异常
* 选择数据库节点服务器，查看节点的CPU,内存，磁盘，网络是否异常
* 选择中间件节点服务器，查看节点的CPU,内存，磁盘，网络是否异常
* 到MySql -> MySql Overview 中查看 QPS、当前连接数、最大连接数、使用线程数、排序次数、网络流量、Innodb内存、慢查询个数、查询类型（是否全表扫描等）、是否异常
* 到HA -> PXC/Galera Cluster Overview 查看集群节点个数、是否发生流控，发生后是否恢复、发生流控次数、集群复制的数据量，FC_limit值大小等是否发生异常

#### 数据库的慢查询配置，及查看分析。使用pt工具

pt 参数介绍
```
pt-query-digest [OPTIONS] [FILES] [DSN]
--create-review-table 当使用--review参数把分析结果输出到表中时，如果没有表就自动创建。
--create-history-table 当使用--history参数把分析结果输出到表中时，如果没有表就自动创建。
--filter 对输入的慢查询按指定的字符串进行匹配过滤后再进行分析
--limit 限制输出结果百分比或数量，默认值是20,即将最慢的20条语句输出，如果是50%则按总响应时间占比从大到小排序，输出到总和达到50%位置截止。
--host mysql服务器地址
--user mysql用户名
--password mysql用户密码
--history 将分析结果保存到表中，分析结果比较详细，下次再使用--history时，如果存在相同的语句，且查询所在的时间区间和历史表中的不同，则会记录到数据表中，可以通过查询同一CHECKSUM来比较某类型查询的历史变化。
--review 将分析结果保存到表中，这个分析只是对查询条件进行参数化，一个类型的查询一条记录，比较简单。当下次使用--review时，如果存在相同的语句分析，就不会记录到数据表中。
--output 分析结果输出类型，值可以是report(标准分析报告)、slowlog(Mysql slow log)、json、json-anon，一般使用report，以便于阅读。
--since 从什么时间开始分析，值为字符串，可以是指定的某个”yyyy-mm-dd [hh:mm:ss]”格式的时间点，也可以是简单的一个时间值：s(秒)、h(小时)、m(分钟)、d(天)，如12h就表示从12小时前开始统计。
--until 截止时间，配合—since可以分析一段时间内的慢查询。
```
用法示例

```
1.直接分析慢查询文件:
pt-query-digest slow.log > slow_report.log

2.分析最近12小时内的查询：
pt-query-digest --since=12h slow.log > slow_report2.log

3.分析指定时间范围内的查询：
pt-query-digest slow.log --since '2017-01-07 09:30:00' --until '2017-01-07 10:00:00'> > slow_report3.log

4.分析指含有select语句的慢查询
pt-query-digest --filter '$event->{fingerprint} =~ m/^select/i' slow.log> slow_report4.log

5.针对某个用户的慢查询
pt-query-digest --filter '($event->{user} || "") =~ m/^root/i' slow.log> slow_report5.log

6.查询所有所有的全表扫描或full join的慢查询
pt-query-digest --filter '(($event->{Full_scan} || "") eq "yes") ||(($event->{Full_join} || "") eq "yes")' slow.log> slow_report6.log
```

#### Tomcat 无响应排查

1. 查看当前正在运行的tomcat线程，是否出现大面积响应慢，明确是因为压力大还是后台响应慢
2. jmap 查看当前运行状态，是否有空间内存不足等问题

#### jvm 内存泄露排查


1. jps -l 查询java 进程的pid 
2. jmap -dump:format=b,file=marketing.bin  #进程ID ,导出dump文件，如果正在运行的容器中没有 jdk命令，可以docker cp 从宿主机复制到容器中使用。将dump文件压缩zip后 传输到电脑上
3. 使用 "MemoryAnalyzer-1.7.0.20170613-win32.win32.x86_64" 软件打开dump文件， 通过list_objects 查找哪些对象最多。可发现对象内存泄漏，如：java.util.zip.Infater 对象特别多，最后发现是zip解压缩后未关闭连接导致内存溢出。

#### JVM CPU 过高排查

* 通过审计工具查看正在执行的URL 初步判断是哪个请求导致CPU过高
1. jps -l 查询java 进程的pid 
2. top -Hbp 9702 | awk '/java/ && $9>50'  查看该进程的线程使用CPU情况，CPU >50%, 该值可根据实际情况调整
3. printf "%x\n" 10007 ， 将线程ID 转换成16进制
4. 使用命令 jstack $pid | grep “线程id” 把信息打印出来， 根据出现问题的代码进行整改即可
